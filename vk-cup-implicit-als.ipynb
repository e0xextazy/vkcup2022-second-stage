{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os; os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.evaluation import mean_average_precision_at_k, ndcg_at_k\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import gc\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train упорядочен хронологически\n",
    "# timespent: время залипания юзера на айтем в минутах (от 0 до 60)\n",
    "# reaction: (1) - лайк, (-1) - дизлайк\n",
    "train = pd.read_parquet('misha_data/train_2degree_value.parquet.gzip')\n",
    "# train = train.reset_index().rename(columns={\"index\": \"time\"}) # set discrete time\n",
    "# train['user_time'] = train.groupby('user_id').cumcount() # set user-wise discrete time\n",
    "\n",
    "# train = train[train.timespent > 0] # sample filters\n",
    "# train = train[train.reaction != -1]\n",
    "\n",
    "ALL_USERS = train['user_id'].unique().tolist()\n",
    "ALL_ITEMS = train['item_id'].unique().tolist()\n",
    "\n",
    "user_ids = dict(list(enumerate(ALL_USERS)))\n",
    "item_ids = dict(list(enumerate(ALL_ITEMS)))\n",
    "\n",
    "user_map = {u: uidx for uidx, u in user_ids.items()}\n",
    "item_map = {i: iidx for iidx, i in item_ids.items()}\n",
    "\n",
    "train['user_id_new'] = train['user_id'].map(user_map)\n",
    "train['item_id_new'] = train['item_id'].map(item_map)\n",
    "\n",
    "print(\"len rows: \", train.shape[0])\n",
    "print(\"Unique users: \", train.user_id.nunique())\n",
    "print(\"Unique items: \", train.item_id.nunique())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timespent</th>\n",
       "      <th>reaction</th>\n",
       "      <th>user_time</th>\n",
       "      <th>user_id_new</th>\n",
       "      <th>item_id_new</th>\n",
       "      <th>user_time_norm_nlinear</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>707536</td>\n",
       "      <td>67950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>707536</td>\n",
       "      <td>151002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>707536</td>\n",
       "      <td>134736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>707536</td>\n",
       "      <td>196151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>707536</td>\n",
       "      <td>94182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  user_id  item_id  timespent  reaction  user_time  user_id_new  \\\n",
       "0     0   707536    67950          0         0          0            0   \n",
       "1     1   707536   151002          0         0          1            0   \n",
       "2     2   707536   134736          0         0          2            0   \n",
       "3     3   707536   196151          0         0          3            0   \n",
       "4     4   707536    94182          0         0          4            0   \n",
       "\n",
       "   item_id_new  user_time_norm_nlinear  value  \n",
       "0            0                0.000000    1.0  \n",
       "1            1                0.000008    1.0  \n",
       "2            2                0.000033    1.0  \n",
       "3            3                0.000074    1.0  \n",
       "4            4                0.000132    1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['value'] = 1 + train.user_time_norm_nlinear * 40 * train.timespent # data for impact in als\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len rows:  227606\n",
      "Unique items:  227606\n",
      "Unique writers:  24438\n",
      "emb shape:  (312,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7340</td>\n",
       "      <td>[0.10458118, 0.047880154, 0.030944156, -0.0351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6284</td>\n",
       "      <td>[0.035625108, -0.039264094, -0.03310334, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12766</td>\n",
       "      <td>[0.08418761, 0.006732465, -0.0037112322, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14734</td>\n",
       "      <td>[0.049901545, 0.039079394, -0.03890682, -0.053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22557</td>\n",
       "      <td>[0.09303163, 0.023448057, 0.0029488814, -0.017...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  source_id                                         embeddings\n",
       "0        0       7340  [0.10458118, 0.047880154, 0.030944156, -0.0351...\n",
       "1        1       6284  [0.035625108, -0.039264094, -0.03310334, -0.04...\n",
       "2        2      12766  [0.08418761, 0.006732465, -0.0037112322, -0.02...\n",
       "3        3      14734  [0.049901545, 0.039079394, -0.03890682, -0.053...\n",
       "4        4      22557  [0.09303163, 0.023448057, 0.0029488814, -0.017..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в items_meta для каждого item_id его автор и эмбеддинг содержания\n",
    "items_meta = pd.read_parquet('items_meta.parquet.gzip')\n",
    "print(\"len rows: \", items_meta.shape[0])\n",
    "print(\"Unique items: \", items_meta.item_id.nunique())\n",
    "print(\"Unique writers: \", items_meta.source_id.nunique())\n",
    "print(\"emb shape: \", items_meta.iloc[0].embeddings.shape)\n",
    "items_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len rows:  100000\n",
      "Items for predict:  100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id\n",
       "0        0\n",
       "1        2\n",
       "2        5\n",
       "3        6\n",
       "4        7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# candidates содержит item_id свежих кандидатов из которых нужно будет предсказать на тесте\n",
    "candidates_df = pd.read_parquet('fresh_candidates.parquet.gzip')\n",
    "print(\"len rows: \", candidates_df.shape[0])\n",
    "print(\"Items for predict: \", candidates_df.item_id.nunique())\n",
    "candidates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:07<00:00, 13397.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find author's items\n",
    "author_items = collections.defaultdict(list)\n",
    "max_len = 0\n",
    "\n",
    "tmp = items_meta[items_meta.item_id.isin(candidates_df.item_id.values)]\n",
    "\n",
    "for id, row in tqdm(tmp.iterrows(), total=tmp.shape[0]):\n",
    "    author_items[row.source_id].append(row.item_id)\n",
    "    l = len(author_items[row.source_id])\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "\n",
    "del tmp\n",
    "gc.collect()\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len rows:  200000\n",
      "Test users:  200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id\n",
       "0        7\n",
       "1        8\n",
       "2        9\n",
       "3       11\n",
       "4       18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet('test.parquet.gzip')\n",
    "print(\"len rows: \", test.shape[0])\n",
    "print(\"Test users: \", test.user_id.nunique())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.95 s, sys: 3.05 s, total: 13 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_size = 0.2\n",
    "\n",
    "val_df = train[train.time >= train.quantile(1 - val_size)[\"time\"]]\n",
    "train_df = train[train.time < train.quantile(1 - val_size)[\"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val size users:  786401\n",
      "Train size users:  991224\n",
      "Intersection size users:  777442\n"
     ]
    }
   ],
   "source": [
    "print(\"Val size users: \", len(set(val_df.user_id.unique())))\n",
    "print(\"Train size users: \", len(set(train_df.user_id.unique())))\n",
    "print(\"Intersection size users: \", len(set(val_df.user_id.unique()).intersection(set(train_df.user_id.unique()))))\n",
    "# Val size users:  685906\n",
    "# Train size users:  797996\n",
    "# Intersection size users:  683719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_user_item_coo(df):\n",
    "    \"\"\" Turn a dataframe with transactions into a COO sparse items x users matrix\"\"\"\n",
    "    row = df['user_id_new'].values\n",
    "    col = df['item_id_new'].values\n",
    "    data = df['value'].values\n",
    "    coo = coo_matrix((data, (row, col)), shape=(len(ALL_USERS), len(ALL_ITEMS)))\n",
    "    return coo\n",
    "\n",
    "\n",
    "def split_data(df, validation_size=0.15):\n",
    "    \"\"\" Split a pandas dataframe into training and validation data, using <<validation_days>>\n",
    "    \"\"\"\n",
    "    validation_cut = df.shape[0] * (1 - validation_size)\n",
    "\n",
    "    df_train = df[df['time'] < validation_cut]\n",
    "    df_val = df[df['time'] >= validation_cut]\n",
    "    return df_train, df_val\n",
    "\n",
    "def get_val_matrices(df, validation_size=0.15):\n",
    "    \"\"\" Split into training and validation and create various matrices\n",
    "        \n",
    "        Returns a dictionary with the following keys:\n",
    "            coo_train: training data in COO sparse format and as (users x items)\n",
    "            csr_train: training data in CSR sparse format and as (users x items)\n",
    "            csr_val:  validation data in CSR sparse format and as (users x items)\n",
    "    \n",
    "    \"\"\"\n",
    "    df_train, df_val = split_data(df, validation_size=validation_size)\n",
    "    coo_train = to_user_item_coo(df_train)\n",
    "    coo_val = to_user_item_coo(df_val)\n",
    "\n",
    "    csr_train = coo_train.tocsr()\n",
    "    csr_val = coo_val.tocsr()\n",
    "    \n",
    "    return {'coo_train': coo_train,\n",
    "            'csr_train': csr_train,\n",
    "            'csr_val': csr_val\n",
    "          }\n",
    "\n",
    "\n",
    "def validate(matrices, factors=200, iterations=20, regularization=0.01, alpha=40, show_progress=True):\n",
    "    \"\"\" Train an ALS model with <<factors>> (embeddings dimension) \n",
    "    for <<iterations>> over matrices and validate with MAP@12\n",
    "    \"\"\"\n",
    "    coo_train, csr_train, csr_val = matrices['coo_train'], matrices['csr_train'], matrices['csr_val']\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=42,\n",
    "                                                 alpha=alpha,\n",
    "                                                 use_gpu=True)\n",
    "    model.fit(csr_train, show_progress=show_progress)\n",
    "    \n",
    "    # The MAPK by implicit doesn't allow to calculate allowing repeated items, which is the case.\n",
    "    # TODO: change MAP@12 to a library that allows repeated items in prediction\n",
    "    ndcg20 = ndcg_at_k(model, csr_train, csr_val, K=20, show_progress=show_progress, num_threads=4)\n",
    "    map20 = mean_average_precision_at_k(model, csr_train, csr_val, K=20, show_progress=show_progress, num_threads=4)\n",
    "    print(f\"Factors: {factors:>3} - Iterations: {iterations:>2} - Regularization: {regularization:4.3f} - Alpha: {alpha} ==> NDCG@20: {ndcg20:6.5f} ==> MAP@20: {map20:6.5f}\")\n",
    "    return ndcg20, map20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrices = get_val_matrices(train) # get train/val matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors: 300 - Iterations:  7 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08626 ==> MAP@20: 0.03231\n",
      "Best NDCG@20 found. Updating: {'factors': 300, 'iterations': 7, 'regularization': 0.001, 'alpha': 1}\n",
      "Best MAP@20 found. Updating: {'factors': 300, 'iterations': 7, 'regularization': 0.001, 'alpha': 1}\n",
      "Factors: 350 - Iterations:  7 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08657 ==> MAP@20: 0.03248\n",
      "Best NDCG@20 found. Updating: {'factors': 350, 'iterations': 7, 'regularization': 0.001, 'alpha': 1}\n",
      "Best MAP@20 found. Updating: {'factors': 350, 'iterations': 7, 'regularization': 0.001, 'alpha': 1}\n",
      "Factors: 400 - Iterations:  7 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08676 ==> MAP@20: 0.03256\n",
      "Best NDCG@20 found. Updating: {'factors': 400, 'iterations': 7, 'regularization': 0.001, 'alpha': 1}\n",
      "Best MAP@20 found. Updating: {'factors': 400, 'iterations': 7, 'regularization': 0.001, 'alpha': 1}\n",
      "Factors: 450 - Iterations:  7 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08659 ==> MAP@20: 0.03250\n",
      "Factors: 300 - Iterations:  8 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08628 ==> MAP@20: 0.03228\n",
      "Factors: 350 - Iterations:  8 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08661 ==> MAP@20: 0.03246\n",
      "Factors: 400 - Iterations:  8 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08681 ==> MAP@20: 0.03256\n",
      "Best NDCG@20 found. Updating: {'factors': 400, 'iterations': 8, 'regularization': 0.001, 'alpha': 1}\n",
      "Factors: 450 - Iterations:  8 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08671 ==> MAP@20: 0.03253\n",
      "Factors: 300 - Iterations:  9 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08624 ==> MAP@20: 0.03224\n",
      "Factors: 350 - Iterations:  9 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08662 ==> MAP@20: 0.03244\n",
      "Factors: 400 - Iterations:  9 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08681 ==> MAP@20: 0.03253\n",
      "Factors: 450 - Iterations:  9 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08672 ==> MAP@20: 0.03252\n",
      "Factors: 300 - Iterations: 10 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08620 ==> MAP@20: 0.03221\n",
      "Factors: 350 - Iterations: 10 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08659 ==> MAP@20: 0.03241\n",
      "Factors: 400 - Iterations: 10 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08678 ==> MAP@20: 0.03250\n",
      "Factors: 450 - Iterations: 10 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08673 ==> MAP@20: 0.03250\n",
      "Factors: 300 - Iterations: 11 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08615 ==> MAP@20: 0.03217\n",
      "Factors: 350 - Iterations: 11 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08656 ==> MAP@20: 0.03237\n",
      "Factors: 400 - Iterations: 11 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08676 ==> MAP@20: 0.03247\n",
      "Factors: 450 - Iterations: 11 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08673 ==> MAP@20: 0.03248\n",
      "Factors: 300 - Iterations: 12 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08610 ==> MAP@20: 0.03213\n",
      "Factors: 350 - Iterations: 12 - Regularization: 0.001 - Alpha: 1 ==> NDCG@20: 0.08650 ==> MAP@20: 0.03233\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-7114f1ffd5d9>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(matrices, factors, iterations, regularization, alpha, show_progress)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# The MAPK by implicit doesn't allow to calculate allowing repeated items, which is the case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# TODO: change MAP@12 to a library that allows repeated items in prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mndcg20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndcg_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mmap20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_average_precision_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Factors: {factors:>3} - Iterations: {iterations:>2} - Regularization: {regularization:4.3f} - Alpha: {alpha} ==> NDCG@20: {ndcg20:6.5f} ==> MAP@20: {map20:6.5f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mevaluation.pyx\u001b[0m in \u001b[0;36mimplicit.evaluation.ndcg_at_k\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mevaluation.pyx\u001b[0m in \u001b[0;36mimplicit.evaluation.ranking_metrics_at_k\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/implicit/gpu/matrix_factorization_base.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, userid, user_items, N, filter_already_liked_items, filter_items, recalculate_user, items)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# calculate the top N items, removing the users own liked items from the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         ids, scores = self.knn.topk(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mitem_factors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0muser_factors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# params tuning\n",
    "best_ndcg20 = 0\n",
    "best_map20 = 0\n",
    "for iterations in range(7, 16):\n",
    "    for factors in [300, 350, 400, 450]:\n",
    "        for regularization in [0.001]:\n",
    "            for alpha in [1]:\n",
    "                ndcg20, map20 = validate(matrices, factors, iterations, regularization, alpha, show_progress=False)\n",
    "                if ndcg20 > best_ndcg20:\n",
    "                    best_ndcg20 = ndcg20\n",
    "                    best_params_ndcg = {'factors': factors, 'iterations': iterations, 'regularization': regularization, 'alpha': alpha}\n",
    "                    print(f\"Best NDCG@20 found. Updating: {best_params_ndcg}\")\n",
    "                if map20 > best_map20:\n",
    "                    best_map20 = map20\n",
    "                    best_params_map = {'factors': factors, 'iterations': iterations, 'regularization': regularization, 'alpha': alpha}\n",
    "                    print(f\"Best MAP@20 found. Updating: {best_params_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coo_train = to_user_item_coo(train)\n",
    "csr_train = coo_train.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(coo_train, factors=200, iterations=15, regularization=0.01, alpha=40, show_progress=True):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors, \n",
    "                                                 iterations=iterations, \n",
    "                                                 regularization=regularization, \n",
    "                                                 random_state=1945,\n",
    "                                                 alpha=alpha, \n",
    "                                                 use_gpu=True\n",
    "                                                )\n",
    "    model.fit(coo_train, show_progress=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'factors': 400, 'iterations': 9, 'regularization': 0.001, 'alpha': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = train(csr_train, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm items:  100000\n"
     ]
    }
   ],
   "source": [
    "items_for_pred = []\n",
    "for item in candidates_df.item_id.tolist():\n",
    "    try:\n",
    "        items_for_pred.append(item_map[item])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"warm items: \", len(items_for_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm users:  200000\n",
      "cold users:  0\n"
     ]
    }
   ],
   "source": [
    "warm_users = []\n",
    "cold_users = []\n",
    "for user in test.user_id.tolist():\n",
    "    try:\n",
    "        warm_users.append(user_map[user])\n",
    "    except:\n",
    "        cold_users.append(user)\n",
    "\n",
    "print(\"warm users: \", len(warm_users))\n",
    "print(\"cold users: \", len(cold_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(model, csr_train, submission_name=\"sub.parquet.gzip\"):\n",
    "    preds = []\n",
    "    most_populars = [4628, 103927, 146586, 18584, 75560, 44269, 58977, 227420, 130953, 11244, 130122, 173607, 121430, 195239, 73059, 52801, 105708, 224095, 55854, 24951]\n",
    "\n",
    "    ids, scores = model.recommend(\n",
    "        warm_users, \n",
    "        csr_train[warm_users], \n",
    "        N=20+max_len, \n",
    "        filter_already_liked_items=True, \n",
    "        items=items_for_pred)\n",
    "    \n",
    "    for i, userid in enumerate(warm_users):\n",
    "        user_id = user_ids[userid]\n",
    "        user_items = ids[i]\n",
    "        article_ids = [item_ids[item_id] for item_id in user_items]\n",
    "        filter_items = author_items[user_id]\n",
    "        article_ids = [item for item in article_ids if item not in filter_items]\n",
    "        preds.append((user_id, article_ids[:20]))\n",
    "        \n",
    "    for userid in cold_users:\n",
    "        preds.append((userid, most_views))            \n",
    "\n",
    "    df_preds = pd.DataFrame(preds, columns=['user_id', 'predictions'])\n",
    "    \n",
    "    df_preds.to_parquet(submission_name, compression='gzip')\n",
    "    \n",
    "    display(df_preds.head())\n",
    "    print(df_preds.shape)\n",
    "    \n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[115127, 77577, 63017, 221001, 162251, 194570,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[142183, 97249, 44222, 216317, 134460, 163702,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[32474, 63495, 227299, 105130, 61240, 67723, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>[143520, 75961, 180137, 63388, 177667, 211646,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[190377, 120767, 97006, 129830, 189621, 212829...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                        predictions\n",
       "0        7  [115127, 77577, 63017, 221001, 162251, 194570,...\n",
       "1        8  [142183, 97249, 44222, 216317, 134460, 163702,...\n",
       "2        9  [32474, 63495, 227299, 105130, 61240, 67723, 2...\n",
       "3       11  [143520, 75961, 180137, 63388, 177667, 211646,...\n",
       "4       18  [190377, 120767, 97006, 129830, 189621, 212829..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2)\n",
      "CPU times: user 1min 11s, sys: 1.73 s, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_preds = submit(model, csr_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addons, like ranking/reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_preds.explode('predictions').merge(mean_timespent, left_on='predictions', right_on='item_id').drop(columns=['item_id']).sort_values(by=['user_id', 'timespent'], ascending=False).drop(columns=['timespent']).groupby('user_id').agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_parquet('implicit_sub_sort_mean_all.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[2216, 194570, 101739, 12697, 182908, 80394, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[62274, 49912, 190438, 40628, 186181, 53828, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[108363, 63495, 96717, 149513, 113616, 29342, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>[142181, 4305, 152520, 191744, 148826, 31753, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[169890, 2216, 155056, 34251, 182733, 206293, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1000160</td>\n",
       "      <td>[55352, 25218, 52187, 169617, 120338, 220549, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1000165</td>\n",
       "      <td>[11231, 120027, 78285, 14866, 165314, 41068, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1000166</td>\n",
       "      <td>[96284, 126127, 125070, 182908, 135532, 146558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1000168</td>\n",
       "      <td>[32348, 62046, 55382, 179166, 98609, 119088, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>1000172</td>\n",
       "      <td>[225623, 55376, 122434, 41068, 101415, 112442,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                        predictions\n",
       "0             7  [2216, 194570, 101739, 12697, 182908, 80394, 9...\n",
       "1             8  [62274, 49912, 190438, 40628, 186181, 53828, 9...\n",
       "2             9  [108363, 63495, 96717, 149513, 113616, 29342, ...\n",
       "3            11  [142181, 4305, 152520, 191744, 148826, 31753, ...\n",
       "4            18  [169890, 2216, 155056, 34251, 182733, 206293, ...\n",
       "...         ...                                                ...\n",
       "199995  1000160  [55352, 25218, 52187, 169617, 120338, 220549, ...\n",
       "199996  1000165  [11231, 120027, 78285, 14866, 165314, 41068, 2...\n",
       "199997  1000166  [96284, 126127, 125070, 182908, 135532, 146558...\n",
       "199998  1000168  [32348, 62046, 55382, 179166, 98609, 119088, 5...\n",
       "199999  1000172  [225623, 55376, 122434, 41068, 101415, 112442,...\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
